# Scoring Rubric for Strategic Foresight Skill

## Overview

Four dimensions, weighted to reflect the skill's primary purpose: producing rigorous, actionable foresight with high-quality probabilistic forecasts.

| Dimension | Weight | Focus |
|-----------|--------|-------|
| Signal Quality | 25% | Horizon scanning breadth, signal diversity, evidence base |
| Analytical Rigor | 30% | Framework application, depth of analysis, logical coherence |
| Forecast Quality | 25% | STPOT compliance, calibration, base rates, Tetlock commandments |
| Actionability | 20% | Decision-relevance, clarity, strategic options, indicators to watch |

---

## Dimension 1: Signal Quality (25%)

### 5 — Excellent
- Signals cover all selected STEEP dimensions with no significant gaps
- Signal types are diverse: trends, weak signals, wild cards, drivers, and uncertainties all represented
- Evidence base includes T1/T2 sources for key signals
- Cross-dimensional interactions identified and analyzed
- Weak signals given appropriate weight — not buried under dominant trends
- Signal direction, pace, and confidence assessed for each

### 4 — Good
- Signals cover all selected STEEP dimensions
- At least 3 signal types represented
- Mix of source tiers with T1/T2 present
- Some cross-dimensional interactions noted
- Minor gaps in coverage that don't undermine the analysis

### 3 — Adequate
- Most STEEP dimensions covered but 1 may be thin
- Signal types lean toward trends with few weak signals or wild cards
- Source quality acceptable but could be stronger
- Limited cross-dimensional analysis
- Sufficient for the mode but not comprehensive

### 2 — Below Expectations
- 2+ STEEP dimensions missing or superficial
- Signal types dominated by trends — weak signals and wild cards absent
- Source quality issues (mostly T4/T5)
- No cross-dimensional analysis
- Significant evidence gaps

### 1 — Poor
- Scanning is shallow — few signals identified
- STEEP dimensions not systematically covered
- Sources are low quality or fabricated
- No signal classification or assessment
- Insufficient evidence base for analysis

---

## Dimension 2: Analytical Rigor (30%)

### 5 — Excellent
- All mode-required frameworks applied correctly and in depth
- Three Horizons presented in H1-H3-H2 order with H2+/H2- distinction
- CLA reaches myth/metaphor level with genuine insight
- Scenarios are internally consistent, genuinely different, and include at least one that challenges conventional wisdom
- Analysis is traceable: every conclusion maps to specific signals and evidence
- Competing hypotheses explicitly considered for each major uncertainty
- GMA, backcasting, and wind tunneling (if applicable) add genuine analytical value

### 4 — Good
- All mode-required frameworks applied correctly
- Three Horizons and CLA are complete with meaningful content at all levels
- Scenarios are internally consistent and distinct
- Most conclusions are traceable to evidence
- Some competing hypotheses considered
- Minor analytical gaps that don't undermine the overall analysis

### 3 — Adequate
- Frameworks applied but some are superficial
- Three Horizons present but H2+/H2- distinction may be weak
- CLA present but worldview/myth levels may be thin
- Scenarios are plausible but may not span the full possibility space
- Traceability adequate but some analytical leaps present
- Competing hypotheses mentioned but not deeply explored

### 2 — Below Expectations
- Some frameworks missing or applied incorrectly
- Three Horizons or CLA incomplete
- Scenarios may be internally inconsistent or too similar to each other
- Significant analytical leaps without evidence support
- Little consideration of competing hypotheses
- Framework application feels mechanical rather than insightful

### 1 — Poor
- Frameworks missing or fundamentally misapplied
- Analysis is narrative-driven without structured methodology
- Scenarios are implausible or contradictory
- Conclusions not traceable to evidence
- No competing hypotheses considered
- Would not withstand expert review

---

## Dimension 3: Forecast Quality (25%)

### 5 — Excellent
- All forecasts fully STPOT-compliant
- Probabilities use the full range appropriate to uncertainty (not clustered at 50% or extremes)
- Base rates identified and used as anchors for most forecasts
- Resolution criteria are specific enough for scoring on a prediction platform
- Tetlock 10 Commandments self-assessment shows mostly Pass with documented reasoning
- Scenario probabilities sum to ~100%
- Cognitive bias checklist completed with specific mitigations documented
- Forecasts demonstrate genuine calibration effort (not false precision or vague hedging)

### 4 — Good
- All forecasts meet STPOT criteria
- Probabilities are specific and reasonably calibrated
- Base rates referenced for most forecasts
- Resolution criteria are clear
- Tetlock self-assessment mostly Pass/Partial
- Minor calibration concerns (e.g., slight clustering at round numbers)

### 3 — Adequate
- Most forecasts meet STPOT criteria with 1-2 minor gaps
- Probabilities are specific but may cluster at round numbers
- Base rates referenced for some forecasts
- Resolution criteria present but could be more specific
- Tetlock self-assessment present but may have several Partial ratings
- Acceptable quality but room for improvement

### 2 — Below Expectations
- Multiple forecasts fail STPOT criteria
- Vague probability language ("likely") mixed with specific numbers
- Few or no base rates referenced
- Resolution criteria vague or missing for some forecasts
- Tetlock self-assessment incomplete or mostly Fail
- Signs of overconfidence or poor calibration

### 1 — Poor
- Forecasts are not STPOT-compliant
- No specific probabilities — vague language throughout
- No base rates or reference classes
- No resolution criteria
- No Tetlock self-assessment
- Forecast section adds no value beyond the scenario narratives

---

## Dimension 4: Actionability (20%)

### 5 — Excellent
- Executive summary is self-contained — a busy decision-maker gets full value from it alone
- Indicators to watch are specific, observable, and linked to data sources
- Strategic options are concrete and linked to specific scenarios/forecasts
- No-regret moves clearly distinguished from big bets (if wind tunneling applied)
- Limitations are honest and specific — the reader knows exactly what they can and can't rely on
- The "so what?" is crystal clear throughout

### 4 — Good
- Executive summary covers key findings and is largely self-contained
- Indicators to watch are specific and actionable
- Strategic implications are clear
- Limitations are substantive
- A decision-maker could act on this report with minor follow-up

### 3 — Adequate
- Executive summary present and covers main points
- Some indicators provided but may lack specific data sources
- Implications section exists but is somewhat generic
- Limitations present but could be more specific
- Useful for orientation but would need supplementation for decision-making

### 2 — Below Expectations
- Executive summary incomplete or doesn't stand alone
- Indicators vague or missing
- Implications section generic ("decision-makers should pay attention to...")
- Limitations perfunctory
- A decision-maker would struggle to extract actionable insights

### 1 — Poor
- No meaningful executive summary
- No indicators to watch
- No strategic implications
- No limitations
- Report is an academic exercise with no decision-relevance

---

## Scoring

### Per-Test Score
Score each dimension 1-5, multiply by weight, sum for a total out of 5.0:

```
Total = (Signal Quality × 0.25) + (Analytical Rigor × 0.30) + (Forecast Quality × 0.25) + (Actionability × 0.20)
```

### Interpretation
| Score | Rating | Meaning |
|-------|--------|---------|
| 4.5-5.0 | Excellent | Professional-grade foresight output |
| 3.5-4.4 | Good | Solid foresight with minor improvements needed |
| 2.5-3.4 | Adequate | Functional but significant room for improvement |
| 1.5-2.4 | Below Expectations | Major quality issues — needs revision |
| 1.0-1.4 | Poor | Fundamental problems — skill may need rework |

### Pass Threshold
- Individual test: ≥ 3.0 overall, no dimension below 2
- Skill validation: ≥ 3.5 average across all 5 tests, no test below 3.0
